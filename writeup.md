# Traffic Sign Recognition Classifier

![Cover](./writeup_imgs/cover.png)

---

## Overview
This project is part of the [Udacity's Self Driving Car Nanodegree](https://www.udacity.com/course/self-driving-car-engineer-nanodegree--nd013). 

A model will be designed, trained, and validated so it can classify traffic sign images using the [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset).

After training the model, it will be tried out on images of German traffic signs randomly selected on the web.

This project's source code can be found [here](https://github.com/miguelangel/sdc--traffic-sign-classifier).

---
## Goals / Steps

The goals / steps of this project are the following:

1. Load the data set from [here](https://s3-us-west-1.amazonaws.com/udacity-selfdrivingcar/traffic-signs-data.zip).
2. Explore, summarize and visualize the data set
3. Design, train and test a model architecture
4. Use the model to make predictions on new images
5. Analyze the softmax probabilities of the new images
6. Summarize the results with a written report


[//]: # (Image References)

[image1]: ./examples/visualization.jpg "Visualization"
[image2]: ./examples/grayscale.jpg "Grayscaling"
[image3]: ./examples/random_noise.jpg "Random Noise"
[image4]: ./examples/placeholder.png "Traffic Sign 1"
[image5]: ./examples/placeholder.png "Traffic Sign 2"
[image6]: ./examples/placeholder.png "Traffic Sign 3"
[image7]: ./examples/placeholder.png "Traffic Sign 4"
[image8]: ./examples/placeholder.png "Traffic Sign 5"

---

## Data Set Summary & Exploration

The German Traffic Sign Dataset is composed by 51839 images, belonging each one to 1 of 43 different categories. 


The dataset is split in training, validation and testing subsets:

| Subset     | # samples |
|------------|-----------|
| Training   |     34799 |
| Validation |      4410 |
| Testing    |     12630 |

The 43 image categories are labeled as follows:

| Label   | Sign name                                          | 
|---------|----------------------------------------------------| 
| 0       | Speed limit (20km/h)                               | 
| 1       | Speed limit (30km/h)                               | 
| 2       | Speed limit (50km/h)                               | 
| 3       | Speed limit (60km/h)                               | 
| 4       | Speed limit (70km/h)                               | 
| 5       | Speed limit (80km/h)                               | 
| 6       | End of speed limit (80km/h)                        | 
| 7       | Speed limit (100km/h)                              | 
| 8       | Speed limit (120km/h)                              | 
| 9       | No passing                                         | 
| 10      | No passing for vehicles over 3.5 metric tons       | 
| 11      | Right-of-way at the next intersection              | 
| 12      | Priority road                                      | 
| 13      | Yield                                              | 
| 14      | Stop                                               | 
| 15      | No vehicles                                        | 
| 16      | Vehicles over 3.5 metric tons prohibited           | 
| 17      | No entry                                           | 
| 18      | General caution                                    | 
| 19      | Dangerous curve to the left                        | 
| 20      | Dangerous curve to the right                       | 
| 21      | Double curve                                       | 
| 22      | Bumpy road                                         | 
| 23      | Slippery road                                      | 
| 24      | Road narrows on the right                          | 
| 25      | Road work                                          | 
| 26      | Traffic signals                                    | 
| 27      | Pedestrians                                        | 
| 28      | Children crossing                                  | 
| 29      | Bicycles crossing                                  | 
| 30      | Beware of ice/snow                                 | 
| 31      | Wild animals crossing                              | 
| 32      | End of all speed and passing limits                | 
| 33      | Turn right ahead                                   | 
| 34      | Turn left ahead                                    | 
| 35      | Ahead only                                         | 
| 36      | Go straight or right                               | 
| 37      | Go straight or left                                | 
| 38      | Keep right                                         | 
| 39      | Keep left                                          | 
| 40      | Roundabout mandatory                               | 
| 41      | End of no passing                                  | 
| 42      | End of no passing by vehicles over 3.5 metric tons | 


In order to obtain these metrics, the following code snippet has been used:

```python
import numpy as np

# Number of training examples
n_train = X_train.shape[0]

# Number of validation examples
n_valid = X_valid.shape[0]

# Number of testing examples.
n_test = X_test.shape[0]

# What's the shape of an traffic sign image?
image_shape = X_train.shape[1:]

# How many unique classes/labels there are in the dataset.
n_classes = np.unique(np.concatenate((y_train, y_valid, y_test))).shape[0]

print("Number of training examples =", n_train)
print("Number of validation examples =", n_valid)
print("Number of testing examples =", n_test)
print("Image data shape =", image_shape)
print("Number of classes =", n_classes)
```

In order to have a better idea about how our dataset is distributes, we have used used [scipy statistical functions](https://docs.scipy.org/doc/scipy/reference/stats.html) and [matplotlib.pyplot plotting framework](https://matplotlib.org/api/pyplot_api.html). 

In the pictures below, it can be observed that the training, validation and testing datasets have a similar _number of examples per label_ distribution, regardless of the _number of samples per label_ is not evenly distributed across each dataset.

![Training Dataset Distribution](./writeup_imgs/dataset_distribution_training.png)

![Validation Dataset Distribution](./writeup_imgs/dataset_distribution_validation.png)


![Testing Dataset Distribution](./writeup_imgs/dataset_distribution_testing.png)

To conclude with our dataset summary and exploration, I will show a small sample of the images. Each of these is a 32x32 with 3 color channels ([RGB](https://es.wikipedia.org/wiki/RGB)).

![Images sample](./writeup_imgs/images_sample.png)

This _collage of images_ has been generated using the code snippet below:

```python
idx = np.random.randint(0, X_train.shape[0], size=36)
fig, axes = plt.subplots(6, 6, sharex=True, sharey=True, figsize=(5,5),)
for ii, ax in zip(idx, axes.flatten()):
    ax.imshow(X_train[ii], aspect='equal')
    ax.xaxis.set_visible(False)
    ax.yaxis.set_visible(False)
plt.subplots_adjust(wspace=0, hspace=0)
```



## Design and Test a Model Architecture

The LeNet-5 network will be used as a basis for this project's solution.

Nevertheless, several changes will be performed to make the network a bit more performant on this dataset.

### Pre-process the Data Set
The image data has been scaled so that the data values are between -1 and 1.

Standardizing either input or target variables tends to make the training process better behaved by improving the numerical condition ([ref.](ftp://ftp.sas.com/pub/neural/illcond/illcond.html)) of the optimization
problem and ensuring that various default values involved in initialization
and termination are appropriate. Standardizing targets can also affect the
objective function.

Please notice that _normalizing_ a vector most often means dividing by a norm of the vector, for example, to make the Euclidean length of the vector equal to one. In the NN literature, _normalizing_ also often refers to rescaling by the minimum
and range of the vector, to make all the elements lie between 0 and 1. In our case, we have chosen to scale between -1 and 1.

For further information, please have a look at [this link](http://www.faqs.org/faqs/ai-faq/neural-nets/part2/) at _Should I normalize/standardize/rescale the data?_ section.

Below it can be seen some sample images before and after scaling them. Please notice that these images do not reflect 100% with the scalation process performed to them. That is due to how [MatPlotLib](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.imshow.html) works. It expects values in the range [0 .. 1] for floats or [0 .. 255] for integers. Out-of-range values are clipped to these bounds.

_Sample images before scaling them_:
![Images sample before scaling them](./writeup_imgs/sample_img_original.png)

_Sample images after scaling them_:
![Images sample after scaling them](./writeup_imgs/sample_img_scaled.png)

Other useful pre-processing techniques include [converting the images to grayscale](https://medium.com/@REInvestor/converting-color-images-to-grayscale-ab0120ea2c1e), [data augmentation](http://cs231n.stanford.edu/reports/2017/pdfs/300.pdf)...


### Model Architecture

My final model is based on the [LeNet](http://yann.lecun.com/exdb/lenet/) architecture:

![Images sample after scaling them](./writeup_imgs/lenet_architecture.png)

Nevertheless, I have modified it to:
   - Accept RGB images of 32x32 instead of grayscale images of 28x28.
   - Classify 43 images instead of 10.
   - Increase its accuracy on this dataset.

In order to increase its accuracy, I have performed the following changes:
   - Use [Leaky_relu](https://www.tensorflow.org/api_docs/python/tf/nn/leaky_relu) activation function instead of [Relu](https://www.tensorflow.org/api_docs/python/tf/nn/relu).
   - Change the second [max_pool](https://www.tensorflow.org/api_docs/python/tf/nn/max_pool) layer by an [avg_pool](https://www.tensorflow.org/api_docs/python/tf/nn/avg_pool) layer.
   - Add [dropout](https://en.wikipedia.org/wiki/Dropout_(neural_networks)) of 0.8 in the last layers to reduce [overfitting](https://en.wikipedia.org/wiki/Overfitting).
   - Use 6 fully connected layers instead of 3.

This is my final model architecture:

| Layer         		|     Description	        					| 
|:---------------------:|:---------------------------------------------:| 
| Input         		| 32x32x3 RGB image   							| 
| Convolutional       	| Input: Input = 32x32x3. Output = 28x28x6. 	|
| Leaky_relu			|												|
| Max pooling	      	| 2x2 stride,  outputs 14x14x6   				|
| Convolutional    	    | Input: Input = 14x14x6. Output = 10x10x16.    |
| Leaky_relu		    |         									    |
| Avg pooling	      	| 2x2 stride, outputs 5x5x16 			    	|
| Flatten				| Input = 5x5x16. Output = 400.					|
| Fully connected	    | Input = 400. Output = 300. 					|	
| Leaky_relu		    |         									    |						
| Fully connected	    | Input = 300. Output = 200. 					|							
| Leaky_relu		    |         									    |						
| Fully connected	    | Input = 200. Output = 120. 					|
| Leaky_relu		    |         									    |						
| Fully connected	    | Input = 120. Output = 84. 					|
| Leaky_relu		    |         									    |						
| Dropout   		    | 0.8     									    |						
| Fully connected	    | Input = 84. Output = 60.   					|
| Leaky_relu		    |         									    |						
| Dropout   		    | 0.8     									    |						
| Fully connected	    | Input = 64. Output = 32.   					|
							


### Model training
During the training step, the [Adam optimizer](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/) is used to try to minimize the [loss](https://en.wikipedia.org/wiki/Loss_function). Loss is calculated by reducing the mean of the [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy) function, which uses the [Softmax function](https://en.wikipedia.org/wiki/Softmax_function) to predict the output between the different 43 categories.

The following hyperparameters have been tuned to improve the model accuracy:
* [learning rate](https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10)
* [epochs](http://www.fon.hum.uva.nl/praat/manual/epoch.html)
* [batch size](https://radiopaedia.org/articles/batch-size-machine-learning)

### Model results

My final model returned a 0.937 accuracy on the validation set, and a 0.933 accuracy on the testing set.

These were the steps I followed to get the results above:

* I first trained the _original_ LeNet architecture with a learning rate of 0.1, a batch size of 128 and a number of epochs of 10.
* Then I changed the activation function from Relu to Leaky_relu. I noticed that there was some improvement (around 0.15), so I decided to keep that activation function.
* Then I started playing different combinations of epochs, batch_size and learning rate.
  * I increased the epochs from 20 to 50, being 50 the best performant.
  * I decreased the learning rate from 0.1 to 0.001, trying 0.01, 0.005 and 0.002. 0.001 was the most performant in term of accuracy.
  *  Decreased the batch size from 128 to 64, which was the selected batch size because it was the most performant in terms of accuracy.
* With the changes above I obtained an increase of the accuracy of around 0.3.
* Then I started adding fully connected layers and dropout until getting the final solution.
* Please notice that the second max_pool layer from the original LeNet architecture has been replaced by an avg_pool layer. It does not increase significantly the accuracy (around 0.1), but it adds up. I also thought it was a beautiful change, so I decided to keep it.

When I decided to increase the number of fully connected layers, I was concerned to overfit the network. That's the reason why I added two dropout layers in the final steps.

### Test a Model on New Images


Here are eight German traffic signs that I found on the web:

![web_sample](./writeup_imgs/web_samples.png)

Please notice that each of the images had a different size. They were rescaled programmatically when loaded.


Here are the results of the prediction:

| Image			        |     Prediction	        					| 
|:---------------------:|:---------------------------------------------:| 
| Yield          		| No passing for vehicles over 3.5 metric tons  | 
| Stop       			| Stop   										|
| Speed limit (70km/h)	| Speed limit (60km/h)							|
| Speed limit (30km/h)	| Speed limit (30km/h)							|
| Speed limit (50km/h)	| Speed limit (30km/h)							|
| Speed limit (60km/h)	| Speed limit (60km/h)							|
| Turn right ahead		| Turn right ahead		 	        			|
| Keep left     		| Keep left                                     |


The model was able to correctly guess 5 of the 8 traffic signs, which gives an accuracy of 62.5%. 

### 5 Top softmax probabilities per prediction

The code for making predictions on my final model is located in the 21th cell of the Ipython notebook.

For the first image, the model is relatively sure that this is a stop sign (probability of 0.6), and the image does contain a stop sign. The top five soft max probabilities were

| Probability         	|     Prediction	        					| 
|:---------------------:|:---------------------------------------------:| 
| .60         			| Stop sign   									| 
| .20     				| U-turn 										|
| .05					| Yield											|
| .04	      			| Bumpy Road					 				|
| .01				    | Slippery Road      							|


For the second image ... 




